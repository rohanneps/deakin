{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7pMJ8Vs8j6M",
        "outputId": "b306abfa-02ef-4a23-a882-82dce76564b4"
      },
      "source": [
        "# install required system dependencies\n",
        "!apt-get install -y xvfb x11-utils \n",
        "!apt-get install x11-utils > /dev/null 2>&1\n",
        "!pip install PyVirtualDisplay==2.0.* \\\n",
        "PyOpenGL==3.1.* \\\n",
        "PyOpenGL-accelerate==3.1.* \\\n",
        "gym[box2d]==0.17.* \n",
        "!pip install pyglet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: PyVirtualDisplay==2.0.* in /usr/local/lib/python3.7/dist-packages (2.0)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Requirement already satisfied: PyOpenGL-accelerate==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from PyVirtualDisplay==2.0.*) (0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M0TFYiQ8oPX"
      },
      "source": [
        "from gym import Env, spaces\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvHIRlR18yQ7"
      },
      "source": [
        "class SteeringWheelEnv(Env):\n",
        "  \"\"\"\n",
        "  Environment to replicate automated steering of the wheel in an environment (road)\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "\n",
        "    # The first set of action is the degree of turn\n",
        "      # -1 indicates complete left turn, 1 indicates complete right turn and 0 indicates wheel is aligned centered\n",
        "    # The second set of action is change in speed of the vehicle.\n",
        "      # Here we will consider 0 as speed reduction and 1 as speed increase \n",
        "    #self.action_space = spaces.MultiDiscrete([3,2])        \n",
        "    self.action_space = spaces.Tuple((\n",
        "                                        spaces.Box(low=np.array([-1]), high=np.array([1])),\n",
        "                                        spaces.Discrete(2)\n",
        "                                      ))\n",
        "\n",
        "\n",
        "    # degree of turn of the road from left(negative) to right(positve)\n",
        "    # self.observation_space = spaces.Box(low=np.array([-1]), high=np.array([1]))    \n",
        "    \n",
        "    # The environment returns \n",
        "      # (Continuous)the amount of turn required for the road ahead. Here -1 indicates left turn, 0 indicates straight road and 1 indicating right turn.\n",
        "      # (Continuous)the position of the vehicle with respect to the current road lane. -1 indicating extreme left, 0 for center and 1 for extreme right\n",
        "    self.observation_space = spaces.Tuple((\n",
        "                                            spaces.Box(low=np.array([-1]), high=np.array([1])),\n",
        "                                            spaces.Box(low=np.array([-1]), high=np.array([1]))\n",
        "                                          ))\n",
        "\n",
        "    # intial randomized turn of the road\n",
        "    self.road_turn = random.uniform(-1,1)\n",
        "    # intial position of vehicle on the orad\n",
        "    self.road_position = random.uniform(-1,1)\n",
        "    # amount of turn Â± from 0 that will be considered almost straight road. Used by the state road_turn\n",
        "    self.turn_margin_to_center = 0.2\n",
        "\n",
        "    # duration of drive\n",
        "    self.drive_duration = 100   # seconds\n",
        "\n",
        "    # margin of error accepted for the vehicle to be considered aligned with the road (center). Used by the state road_position\n",
        "    self.vehicle_road_center_threshold = 0.4\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    # decrease time step\n",
        "    self.drive_duration -= 1\n",
        "\n",
        "    action_turn, action_speed = action        # float, integer\n",
        "\n",
        "    # get updated road postion of vehicle after action execution\n",
        "    self.road_position = self.get_updated_road_position(self.road_position, self.road_turn, action_turn, action_speed)\n",
        "    # assigning default reward to action\n",
        "    reward = -1\n",
        "\n",
        "    if self.road_turn < -self.turn_margin_to_center or self.road_turn > self.turn_margin_to_center:     # road is turning left or right\n",
        "      # when turning need to reduce speed\n",
        "      if action_speed == 0:\n",
        "        if self.road_position>=-self.vehicle_road_center_threshold and self.road_position<=self.vehicle_road_center_threshold:\n",
        "          # wheel and road turn are aligned straight. The vehicle is almost center of the road\n",
        "          reward = 1\n",
        "    else:\n",
        "      # for straight road\n",
        "      if action_turn >= -self.turn_margin_to_center and action_turn <= self.turn_margin_to_center:\n",
        "          # wheel and road turn are aligned straight. The vehicle is almost center of the road\n",
        "          if self.road_position>= -self.vehicle_road_center_threshold and self.road_position<= self.vehicle_road_center_threshold:\n",
        "            reward = 1\n",
        "    \n",
        "    # get next state after action\n",
        "    self.road_turn, self.road_position = self.get_next_state(self.road_turn, self.road_position)\n",
        "    # check if task is done     \n",
        "    if self.drive_duration >0:\n",
        "      task_done = False\n",
        "    else:\n",
        "      task_done = True\n",
        "\n",
        "    return (self.road_turn, self.road_position), reward, task_done, {}\n",
        "\n",
        "  \n",
        "  def get_updated_road_position(self, road_position, road_turn, action_turn, action_speed):\n",
        "    \"\"\"\n",
        "    Return the updated vehicle road position based on turning and speed change action of the agent\n",
        "    \"\"\"\n",
        "    \n",
        "    # NOTE: Probability is used in effect of road turn in position in order to simulate real-world scenarios(noise) \n",
        "    # like misjudged wheel turn, obstacles on road, etc\n",
        "    \n",
        "\n",
        "    update_margin = 0.0\n",
        "    # For left turning road\n",
        "    if road_turn < -self.turn_margin_to_center:    # this means the road_turn is pushing towards -1 (left)\n",
        "      # For low speed\n",
        "      if action_speed == 0:\n",
        "        if action_turn < -self.turn_margin_to_center: \n",
        "          # vehicle also turning left\n",
        "          update_margin = action_turn -road_turn           \n",
        "        elif action_turn > self.turn_margin_to_center:       \n",
        "          # for vehicle turning right in a left turning road\n",
        "          update_margin = (-1*road_turn) + action_turn\n",
        "        else:                     \n",
        "          # for vehicle going straight in a left turning road\n",
        "          update_margin = (-1*road_turn)                # road_turn is negative(towards left) and hence the vehicle position is displaced towards the right (positve)\n",
        "      if action_speed == 1:\n",
        "        # For higher speed, the effect of turn is less\n",
        "        update_margin /= 2 \n",
        "\n",
        "    # For right turning road\n",
        "    elif road_turn > self.turn_margin_to_center:       # this means the road_turn is pushing towards 1 (right)\n",
        "      # For low speed\n",
        "      if action_speed == 0:\n",
        "        if action_turn > self.turn_margin_to_center:       \n",
        "        # vehicle also turning right\n",
        "          update_margin = action_turn - road_turn           \n",
        "        elif action_turn < -self.turn_margin_to_center:    \n",
        "        # for vehicle turning left in a right turning road\n",
        "          update_margin = (-1*road_turn) + action_turn\n",
        "        else:                    \n",
        "        # for vehicle going straight in a right turning road\n",
        "          update_margin = (-1*road_turn)                # road_turn is positive(towards right) and hence the vehicle position is displaced towards the left (negative)\n",
        "      if action_speed == 1:\n",
        "        # For higher speed, the effect of turn is less\n",
        "        update_margin /= 2 \n",
        "    \n",
        "    # For straight road\n",
        "    else:\n",
        "      if action_turn < -self.turn_margin_to_center: \n",
        "        # vehicle turning left\n",
        "        update_margin = action_turn - road_turn             # vehicle moves towards left side of the lane (negative)\n",
        "      elif action_turn > self.turn_margin_to_center:\n",
        "        # vehicle turning right\n",
        "        update_margin = action_turn - road_turn             # vehicle moves towards right side of the lane (positive)\n",
        "      else:\n",
        "        update_margin = 0.0\n",
        "\n",
        "    if update_margin:\n",
        "      road_position += update_margin\n",
        "    return road_position\n",
        "\n",
        "\n",
        "  def get_lower_and_upper_limit(self, val):\n",
        "    \"\"\"\n",
        "    Get next road turn range\n",
        "    \"\"\"\n",
        "    lower_limit = -1\n",
        "    upper_limit = 1\n",
        "    if val - self.turn_margin_to_center>-1:\n",
        "      lower_limit = val - self.turn_margin_to_center\n",
        "    if val + self.turn_margin_to_center<1:\n",
        "      upper_limit = val + self.turn_margin_to_center\n",
        "    return lower_limit, upper_limit\n",
        "\n",
        "\n",
        "  def get_next_state(self, road_turn, road_position):\n",
        "    \"\"\"\n",
        "    Get next state of environment given the current state.\n",
        "    \"\"\"\n",
        "    lower_limit, upper_limit = self.get_lower_and_upper_limit(road_turn)\n",
        "    next_road_turn = random.uniform(lower_limit, upper_limit)\n",
        "\n",
        "    if next_road_turn < -self.turn_margin_to_center:\n",
        "      # For left\n",
        "      road_position += next_road_turn\n",
        "    elif next_road_turn > self.turn_margin_to_center:\n",
        "      road_position += next_road_turn\n",
        "    else:\n",
        "      road_position = road_position   # no change for straight road\n",
        "\n",
        "    if road_position<-1:\n",
        "      road_position = -1\n",
        "    if road_position >1:\n",
        "      road_position = 1\n",
        "    return next_road_turn, road_position\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Reset environment states\n",
        "    \"\"\"\n",
        "    # intial randomized turn of the road\n",
        "    self.road_turn = random.uniform(-1,1)\n",
        "    # intial position of vehicle on the orad\n",
        "    self.road_position = random.uniform(-1,1)\n",
        "    \n",
        "    # reset duration of drive\n",
        "    self.drive_duration = 100   # seconds\n",
        "    return self.road_turn, self.road_position"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFMcdjbg9G4c"
      },
      "source": [
        "def convert_cont_states_to_tuple(state):\n",
        "  \"\"\"\n",
        "  Conversion of continous states to discrete tuple for easier representation and computation\n",
        "  \"\"\"\n",
        "  road_turn, vehicle_road_pos = state\n",
        "  if road_turn <0:\n",
        "    road_turn_dis = -1\n",
        "  elif road_turn >0:\n",
        "    road_turn_dis = 1\n",
        "  else:\n",
        "    road_turn_dis = 0\n",
        "  \n",
        "  if vehicle_road_pos <0:\n",
        "    vehicle_road_pos_dis = -1\n",
        "  elif vehicle_road_pos >0:\n",
        "    vehicle_road_pos_dis = 1\n",
        "  else:\n",
        "    vehicle_road_pos_dis = 0\n",
        "  \n",
        "  return road_turn_dis,vehicle_road_pos_dis\n",
        "\n",
        "def get_vehicle_turn_cont_val(action, obs):\n",
        "  \"\"\"\n",
        "  Returns the turn of wheel continuous action value based on discrete action obtained from optimal policy\n",
        "  \"\"\"\n",
        "  road_turn, vehicle_road_pos = obs\n",
        "  diff = road_turn - vehicle_road_pos\n",
        "  if action[-2] == 'r':       # needs right turn\n",
        "    return diff\n",
        "  elif action[-2] == 'l':     # needs lef turn\n",
        "    return diff\n",
        "  else:\n",
        "    return random.uniform(-.2,.2)\n",
        "\n",
        "\n",
        "def get_speed_discrete_val(action):\n",
        "  \"\"\"\n",
        "  getting binary speed action value\n",
        "  \"\"\"\n",
        "  if action[-1] == 'i':     # indicates action to increase speed\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_continuous_actions_from_discrete(discrete_action, state):\n",
        "  speed = get_speed_discrete_val(discrete_action)\n",
        "  turn = get_vehicle_turn_cont_val(discrete_action, state)\n",
        "  return turn, speed "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlf7RtUD6iu"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.theta = np.random.randn(37) / np.sqrt(37)\n",
        "\n",
        "  def sa2x(self, s, a):\n",
        "    # For feature vector representation we have \n",
        "    # 6 features * 6 actions + 1 bias = 37\n",
        "    return np.array([\n",
        "        s[0]/3.                   if a == 'a_lr' else 0,\n",
        "        s[1]/3.                   if a == 'a_lr' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_lr' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_lr' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_lr' else 0,\n",
        "        1                         if a == 'a_lr' else 0,\n",
        "        s[0]/3.                   if a == 'a_li' else 0,\n",
        "        s[1]/3.                   if a == 'a_li' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_li' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_li' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_li' else 0,\n",
        "        1                         if a == 'a_li' else 0,\n",
        "        s[0]/3.                   if a == 'a_rr' else 0,\n",
        "        s[1]/3.                   if a == 'a_rr' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_rr' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_rr' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_rr' else 0,\n",
        "        1                         if a == 'a_rr' else 0,\n",
        "        s[0]/3.                   if a == 'a_ri' else 0,\n",
        "        s[1]/3.                   if a == 'a_ri' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_ri' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_ri' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_ri' else 0,\n",
        "        1                         if a == 'a_ri' else 0,\n",
        "        s[0]/3.                   if a == 'a_cr' else 0,\n",
        "        s[1]/3.                   if a == 'a_cr' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_cr' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_cr' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_cr' else 0,\n",
        "        1                         if a == 'a_cr' else 0,\n",
        "        s[0]/3.                   if a == 'a_ci' else 0,\n",
        "        s[1]/3.                   if a == 'a_ci' else 0,\n",
        "        s[0]*s[1]/9.              if a == 'a_ci' else 0,\n",
        "        s[0]*s[0]/9.              if a == 'a_ci' else 0,\n",
        "        s[1]*s[1]/9.              if a == 'a_ci' else 0,\n",
        "        1                         if a == 'a_ci' else 0,\n",
        "        1\n",
        "    ])\n",
        "\n",
        "  def predict(self, s, a):\n",
        "    x = self.sa2x(s, a)\n",
        "    return self.theta.dot(x)\n",
        "\n",
        "  def grad(self, s, a):\n",
        "    return self.sa2x(s, a)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7jlk6N_CQKp"
      },
      "source": [
        "# POSSIBLE DISCRETE ACTIONS\n",
        "ALL_POSSIBLE_ACTIONS = ['a_lr', 'a_li', 'a_rr', 'a_ri', 'a_cr',  'a_ci']\n",
        "SMALL_ENOUGH = 1e-3\n",
        "GAMMA = 0.9\n",
        "ALPHA = 0.1\n",
        "SA2IDX = {}\n",
        "IDX = 0\n",
        "\n",
        "# Initialize the model\n",
        "model = Model()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q5QgdCm9Pbb"
      },
      "source": [
        "def max_dict(d):\n",
        "  # returns the argmax (key) and max (value) from a dictionary\n",
        "  max_key = None\n",
        "  max_val = float('-inf')\n",
        "  for k, v in d.items():\n",
        "    if v > max_val:\n",
        "      max_val = v\n",
        "      max_key = k\n",
        "  return max_key, max_val\n",
        "\n",
        "def random_action(a, eps=0.1):\n",
        "  # epsilon-soft to ensure all states are visited\n",
        "  p = np.random.random()\n",
        "  if p < (1 - eps):\n",
        "    return a\n",
        "  else:\n",
        "    return np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
        "\n",
        "\n",
        "def getQs(model, s):\n",
        "  \"\"\"\n",
        "  prediction of state-action value function\n",
        "  # we need Q(s,a) to choose an action\n",
        "  # i.e. a = argmax[a]{ Q(s,a) \n",
        "  \"\"\"\n",
        "  Qs = {}\n",
        "  for a in ALL_POSSIBLE_ACTIONS:\n",
        "    q_sa = model.predict(s, a)\n",
        "    Qs[a] = q_sa\n",
        "  return Qs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj4iSeRJ-TEj",
        "outputId": "a9b9028c-1ac9-4192-a6e8-a2bdc4979023"
      },
      "source": [
        "env = SteeringWheelEnv()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA97rnfv9-fP",
        "outputId": "0344db29-1061-4794-fd37-ab3f3f25538c"
      },
      "source": [
        "# SEMI GRADIENT SARSA(0)\n",
        "\n",
        "# repeat until convergence\n",
        "t = 1.0\n",
        "t2 = 1.0\n",
        "deltas = []\n",
        "\n",
        "for it in range(10000):\n",
        "  if it % 100 == 0:\n",
        "    t += 0.01\n",
        "    t2 += 0.01\n",
        "  if it % 1000 == 0:\n",
        "    print(\"iteration:\", it)\n",
        "  alpha = ALPHA / t2\n",
        "\n",
        "  s = env.reset()\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "  # conversion of continuous states to tuple of discrete states\n",
        "  s = convert_cont_states_to_tuple(s)\n",
        "\n",
        "  # get Q(s) so we can choose the first action\n",
        "  Qs = getQs(model, s)\n",
        "  # the first (s, r) tuple is the state we start in and 0\n",
        "  # (since we don't get a reward) for simply starting the game\n",
        "  # the last (s, r) tuple is the terminal state and the final reward\n",
        "  # the value for the terminal state is by definition 0, so we don't\n",
        "  # care about updating it.\n",
        "  a = max_dict(Qs)[0]\n",
        "  a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
        "  biggest_change = 0\n",
        "  # while not grid.game_over():\n",
        "  while not done:\n",
        "    # need to convert discrete action to continuous\n",
        "    action = get_continuous_actions_from_discrete(a, s)\n",
        "    s2, r, done, i = env.step(action)\n",
        "    s2 = convert_cont_states_to_tuple(s2)\n",
        "    \n",
        "    # we need the next action as well since Q(s,a) depends on Q(s',a')\n",
        "    # if s2 not in policy then it's a terminal state, all Q are 0\n",
        "    old_theta = model.theta.copy()\n",
        "\n",
        "    if done:\n",
        "      model.theta += alpha*(r - model.predict(s, a))*model.grad(s, a)\n",
        "    else:\n",
        "      # not terminal\n",
        "      Qs2 = getQs(model, s2)\n",
        "      a2, maxQs2a2 = max_dict(Qs2)\n",
        "      a2 = random_action(a2, eps=0.5/t) # epsilon-greed\n",
        "\n",
        "      # we will update Q(s,a) AS we experience the episode\n",
        "      model.theta += alpha*(r + GAMMA*maxQs2a2 - model.predict(s, a))*model.grad(s, a)\n",
        "      \n",
        "      # next state becomes current state\n",
        "      s = s2\n",
        "      a = a2\n",
        "\n",
        "    biggest_change = max(biggest_change, np.abs(model.theta - old_theta).sum())\n",
        "    deltas.append(biggest_change)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration: 0\n",
            "iteration: 1000\n",
            "iteration: 2000\n",
            "iteration: 3000\n",
            "iteration: 4000\n",
            "iteration: 5000\n",
            "iteration: 6000\n",
            "iteration: 7000\n",
            "iteration: 8000\n",
            "iteration: 9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "mSw_oDCrJ1Sx",
        "outputId": "ae44d099-4da8-48d8-c580-eb9dbd4bfe0f"
      },
      "source": [
        "plt.plot(deltas)\n",
        "plt.show()\n",
        "print(model.theta)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-3.60674484e-01 -3.35152863e-01  6.29234011e+00  1.22529669e-02\n",
            " -1.77391843e-02  1.19090024e-01  1.26412924e-01  7.00251747e-03\n",
            "  3.53980097e+00  2.01024009e-02 -5.80177410e-02  2.12676558e-02\n",
            "  4.60548170e-02 -3.05097705e-01  6.23305946e+00  5.46551587e-02\n",
            "  3.89163547e-02  1.26400123e-01  6.37274721e-03 -2.28132857e-02\n",
            "  3.61466799e+00  5.46740627e-03 -6.04013869e-02  7.88697124e-02\n",
            " -8.66062722e-01 -1.01842445e+00  9.27466190e+00  1.32857378e-01\n",
            "  2.54173492e-01 -2.47488101e-01 -1.50968177e-01 -3.91139684e-02\n",
            "  4.24619211e+00  1.21418087e-01 -2.05759275e-01 -4.45349264e-02\n",
            " -2.25559963e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqvl4LOuL0K2"
      },
      "source": [
        " # Obtain Optimal Semi Gradient Sarsa(0) Policy\n",
        "import itertools\n",
        "# determine the policy from Q*\n",
        "# find V* from Q*\n",
        "sarsa_policy = {}\n",
        "sarsa_V = {}\n",
        "sarsa_Q = {}\n",
        "\n",
        "# get all possible state combinations\n",
        "single_state_values = [-1,0,1]\n",
        "possible_states = list(itertools.product(single_state_values, single_state_values))\n",
        "for s in possible_states:\n",
        "  Qs = getQs(model, s)\n",
        "  sarsa_Q[s] = Qs\n",
        "  a, max_q = max_dict(Qs)\n",
        "  sarsa_policy[s] = a\n",
        "  sarsa_V[s] = max_q"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5szK5k1g3mO"
      },
      "source": [
        "def get_optimal_action_from_policy(state, policy):\n",
        "  s = convert_cont_states_to_tuple(state)\n",
        "  discrete_action = policy[s]\n",
        "  action = get_continuous_actions_from_discrete(discrete_action, state)\n",
        "  return action"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To_vhkl-ez-0"
      },
      "source": [
        "# Testing Semi Gradient Sarsa(0) learned policy on custom environment\n",
        "num_iters = 100\n",
        "sarsa_ep_rewards = []\n",
        "for tests in range(num_iters):\n",
        "  obs = env.reset()\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "  while not done:\n",
        "    action = get_optimal_action_from_policy(obs, sarsa_policy)\n",
        "    obs, reward, done, i = env.step(action)\n",
        "    total_reward += reward\n",
        "  # print('Total Reward Collected: {}' .format(total_reward))\n",
        "  sarsa_ep_rewards.append(total_reward)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcm_inDG_pgl"
      },
      "source": [
        "\"\"\"\n",
        "https://github.com/Wongcheukwai/David-Silver-Reinforcement-Learning/blob/master/tile_coding.py\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "Title: Tile Coding\n",
        "Author: Wongcheukwai\n",
        "Date Accessed: May 07, 2021\n",
        "Availability: https://github.com/Wongcheukwai/David-Silver-Reinforcement-Learning/blob/master/tile_coding.py\"\"\"\n",
        "\n",
        "\n",
        "basehash = hash\n",
        "\n",
        "class IHT:\n",
        "    \"Structure to handle collisions\"\n",
        "    def __init__(self, sizeval):\n",
        "        self.size = sizeval\n",
        "        self.overfullCount = 0\n",
        "        self.dictionary = {}\n",
        "\n",
        "    def __str__(self):\n",
        "        \"Prepares a string for printing whenever this object is printed\"\n",
        "        return \"Collision table:\" + \\\n",
        "               \" size:\" + str(self.size) + \\\n",
        "               \" overfullCount:\" + str(self.overfullCount) + \\\n",
        "               \" dictionary:\" + str(len(self.dictionary)) + \" items\"\n",
        "\n",
        "    def count (self):\n",
        "        return len(self.dictionary)\n",
        "\n",
        "    def fullp (self):\n",
        "        return len(self.dictionary) >= self.size\n",
        "\n",
        "    def getindex (self, obj, readonly=False):\n",
        "        d = self.dictionary\n",
        "        if obj in d: return d[obj]\n",
        "        elif readonly: return None\n",
        "        size = self.size\n",
        "        count = self.count()\n",
        "        if count >= size:\n",
        "            if self.overfullCount==0: print('IHT full, starting to allow collisions')\n",
        "            self.overfullCount += 1\n",
        "            return basehash(obj) % self.size\n",
        "        else:\n",
        "            d[obj] = count\n",
        "            return count\n",
        "\n",
        "def hashcoords(coordinates, m, readonly=False):\n",
        "    if type(m)==IHT: return m.getindex(tuple(coordinates), readonly)\n",
        "    if type(m)==int: return basehash(tuple(coordinates)) % m\n",
        "    if m==None: return coordinates\n",
        "\n",
        "from math import floor, log\n",
        "from itertools import zip_longest\n",
        "\n",
        "def tiles (ihtORsize, numtilings, floats, ints=[], readonly=False):\n",
        "    \"\"\"returns num-tilings tile indices corresponding to the floats and ints\"\"\"\n",
        "    qfloats = [floor(f*numtilings) for f in floats]\n",
        "    Tiles = []\n",
        "    for tiling in range(numtilings):\n",
        "        tilingX2 = tiling*2\n",
        "        coords = [tiling]\n",
        "        b = tiling\n",
        "        for q in qfloats:\n",
        "            coords.append( (q + b) // numtilings )\n",
        "            b += tilingX2\n",
        "        coords.extend(ints)\n",
        "        Tiles.append(hashcoords(coords, ihtORsize, readonly))\n",
        "    return Tiles\n",
        "\n",
        "def tileswrap (ihtORsize, numtilings, floats, wrawidths, ints=[], readonly=False):\n",
        "    \"\"\"returns num-tilings tile indices corresponding to the floats and ints, wrapping some floats\"\"\"\n",
        "    qfloats = [floor(f*numtilings) for f in floats]\n",
        "    Tiles = []\n",
        "    for tiling in range(numtilings):\n",
        "        tilingX2 = tiling*2\n",
        "        coords = [tiling]\n",
        "        b = tiling\n",
        "        for q, width in zip_longest(qfloats, wrapwidths):\n",
        "            c = (q + b%numtilings) // numtilings\n",
        "            coords.append(c%width if width else c)\n",
        "            b += tilingX2\n",
        "        coords.extend(ints)\n",
        "        Tiles.append(hashcoords(coords, ihtORsize, readonly))\n",
        "    return Tiles"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZiqYZGPhd73"
      },
      "source": [
        "class LambdaModel():\n",
        "    \"\"\"\n",
        "    Linear action-value (q-value) function approximator for \n",
        "    semi-gradient methods with state-action featurization. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_tilings=8, max_size=37, tiling_dim=None):\n",
        "        \n",
        "        self.max_size = max_size\n",
        "\n",
        "        self.num_tilings = num_tilings\n",
        "        self.tiling_dim = tiling_dim or num_tilings\n",
        "\n",
        "\n",
        "        # Initialize index hash table (IHT) for tile coding.\n",
        "        # This assigns a unique index to each tile up to max_size tiles.\n",
        "        # Ensure max_size >= total number of tiles (num_tilings x tiling_dim x tiling_dim)\n",
        "        # to ensure no duplicates.\n",
        "        self.iht = IHT(max_size)\n",
        "\n",
        "        # Initialize weights and eligibility trace vector\n",
        "        self.weights = np.zeros(max_size)\n",
        "\n",
        "        self.z = np.zeros(max_size)\n",
        "  \n",
        "        # Tilecoding software partitions at integer boundaries, so must rescale\n",
        "        # road_turn and road_position space to span tiling_dim x tiling_dim region.\n",
        "        self.road_turn_scale = self.tiling_dim / (env.observation_space[0].high \\\n",
        "                                                  - env.observation_space[0].low)\n",
        "        self.road_pos_scale = self.tiling_dim / (env.observation_space[1].high \\\n",
        "                                                  - env.observation_space[1].low)\n",
        "        \n",
        "    def featurize_state_action(self, state, action):\n",
        "        \"\"\"\n",
        "        Returns the featurized representation for a \n",
        "        state-action pair.\n",
        "        \"\"\"\n",
        "        featurized = tiles(self.iht, self.num_tilings, \n",
        "                              [\n",
        "                                self.road_turn_scale * state[0], \n",
        "                                self.road_pos_scale * state[1]\n",
        "                              ],[action]\n",
        "                           )\n",
        "        return featurized\n",
        "\n",
        "    # def featurize_state_action(self, state, action):\n",
        "    #     \"\"\"\n",
        "    #     Returns the featurized representation for a \n",
        "    #     state-action pair.\n",
        "    #     Here since we have assumed 3 possible discrete vaues for each state (-1,0 and 1) and there are six actions. We can consider a binary feature array of size 3+3+6. \n",
        "    #     The boolean value of first 3 indices can be thought of as presence of feature .\n",
        "    #     \"\"\"\n",
        "    #     featurize = np.zeros(12)\n",
        "    #     # For 1st state, since discrete value ranges from -1 to 1. Adding 1 to get position\n",
        "    #     featurize[state[0]+1] = 1\n",
        "\n",
        "    #     # For 2nd state, since discrete value ranges from -1 to 1. Adding 3 to get position since 0,1,2 belong to first state\n",
        "    #     featurize[state[1]+3] = 1\n",
        "\n",
        "    #     # For action, since there are 6 possible discrete actions given under ALL_POSSIBLE_ACTIONS. Let us consider the position index of action for featurization\n",
        "    #     featurize[action+6] = 1\n",
        "\n",
        "    #     return featurize\n",
        "\n",
        "    \n",
        "    def predict(self, s, a=None):\n",
        "        \"\"\"\n",
        "        Predicts q-value(s) using linear FA.\n",
        "        \"\"\"\n",
        "        if a is None:\n",
        "            features = [self.featurize_state_action(s, i) for \n",
        "                        i in range(len(ALL_POSSIBLE_ACTIONS))]\n",
        "        else:\n",
        "            features = [self.featurize_state_action(s, a)]\n",
        "        return [np.sum(self.weights[f]) for f in features]\n",
        "        \n",
        "            \n",
        "    def update(self, s, a, target, alpha):\n",
        "        \"\"\"\n",
        "        Updates the weight vector based on the eligibility trace and TD error\n",
        "        \"\"\"\n",
        "        features = self.featurize_state_action(s, a)\n",
        "        estimation = np.sum(self.weights[features])  # Linear FA\n",
        "        delta = (target - estimation)\n",
        "        \n",
        "        # self.z[features] += 1  # Accumulating trace\n",
        "        self.z[features] = 1  # Replacing trace\n",
        "        self.weights += alpha * delta * self.z\n",
        "    \n",
        "\n",
        "    def reset_trace(self):\n",
        "        \"\"\"\n",
        "        Resets the eligibility trace (must be done at the start of every epoch)\n",
        "        \"\"\"\n",
        "        self.z = np.zeros(self.max_size)\n",
        "\n",
        "\n",
        "\n",
        "def make_epsilon_greedy_policy(estimator, epsilon, num_actions):\n",
        "    \"\"\"\n",
        "    Creates an epsilon-greedy policy\n",
        "    \"\"\"\n",
        "    def policy_fn(observation):\n",
        "        action_probs = np.ones(num_actions, dtype=float) * epsilon / num_actions\n",
        "        q_values = estimator.predict(observation)\n",
        "        best_action_idx = np.argmax(q_values)\n",
        "        action_probs[best_action_idx] += (1.0 - epsilon)\n",
        "        return action_probs\n",
        "    return policy_fn"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVj2sRhUqe-L",
        "outputId": "af0d4970-158c-4d57-ab56-ecb656712461"
      },
      "source": [
        "estimator = LambdaModel()\n",
        "lmbda = 0.92  # Level of bootstrapping (set to intermediate value)\n",
        "\n",
        "\n",
        "# repeat until convergence\n",
        "t = 1.0\n",
        "t2 = 1.0\n",
        "sl_deltas = []\n",
        "\n",
        "# For each episode\n",
        "for it in range(1000):\n",
        "  if it % 100 == 0:\n",
        "    t += 0.01\n",
        "    t2 += 0.01\n",
        "  if it % 1000 == 0:\n",
        "    print(\"iteration:\", it)\n",
        "  alpha = ALPHA / t2\n",
        "    \n",
        "  # Reset the eligibility trace\n",
        "  estimator.reset_trace()\n",
        "\n",
        "   # Create epsilon-greedy policy\n",
        "  policy = make_epsilon_greedy_policy(estimator, 0.5/t, len(ALL_POSSIBLE_ACTIONS))\n",
        "  # Reset the environment and pick the first action\n",
        "  s = env.reset()\n",
        "  done = False\n",
        "\n",
        "  # conversion of continuous states to tuple of discrete states\n",
        "  s = convert_cont_states_to_tuple(s)\n",
        "  # random action at start\n",
        "  action_probs = policy(s)\n",
        "  a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  biggest_change = 0\n",
        "  while not done:\n",
        "    # Take a step\n",
        "    # need to convert discrete action to continuous\n",
        "    a = get_continuous_actions_from_discrete(ALL_POSSIBLE_ACTIONS[a], s)\n",
        "    s2, r, done, i = env.step(a)\n",
        "    s2 = convert_cont_states_to_tuple(s2)\n",
        "\n",
        "    old_theta = estimator.weights.copy()\n",
        "    if done:\n",
        "        # terminal state\n",
        "        estimator.update(s, a, r, alpha)\n",
        "    else:\n",
        "      # Take next step\n",
        "      a2_probs = policy(s2)\n",
        "      a2 = np.random.choice(np.arange(len(a2_probs)), p=a2_probs)\n",
        "\n",
        "      # Estimate q-value at next state-action\n",
        "      q2 = estimator.predict(s2, a2)[0]\n",
        "      target = r + GAMMA * q2\n",
        "\n",
        "      # Update weights step\n",
        "      estimator.update(s, a, target, alpha)\n",
        "      estimator.z *= GAMMA * lmbda\n",
        "\n",
        "      s = s2\n",
        "      a = a2\n",
        "\n",
        "    biggest_change = max(biggest_change, np.abs(estimator.weights - old_theta).sum())\n",
        "    sl_deltas.append(biggest_change)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration: 0\n",
            "IHT full, starting to allow collisions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "DeOz_zrLAYqZ",
        "outputId": "5fac4912-2742-4081-d2a5-29af0f401d3c"
      },
      "source": [
        "plt.plot(sl_deltas[::-1])\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnVEWApUEsA3"
      },
      "source": [
        "# Obtaining optimal Sarsa Lambda Policy\n",
        "sarsa_l_policy = {}\n",
        "sarsa_l_V = {}\n",
        "sarsa_l_Q = {}\n",
        "\n",
        "# get all possible state combinations\n",
        "single_state_values = [-1,0,1]\n",
        "possible_states = list(itertools.product(single_state_values, single_state_values))\n",
        "for s in possible_states:\n",
        "  Qs = getQs(estimator, s)\n",
        "  # converting q-value from list with one value to single value\n",
        "  Qs = {k:v[0] for k,v in Qs.items()}\n",
        "  sarsa_l_Q[s] = Qs\n",
        "  a, max_q = max_dict(Qs)\n",
        "  sarsa_l_policy[s] = a\n",
        "  sarsa_l_V[s] = max_q"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDI0RfbLFsuq"
      },
      "source": [
        "# Testing Sarsa lambda learned policy\n",
        "sarsa_l_ep_rewards = []\n",
        "for tests in range(num_iters):\n",
        "  obs = env.reset()\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "  while not done:\n",
        "    action = get_optimal_action_from_policy(obs, sarsa_l_policy)\n",
        "    obs, reward, done, i = env.step(action)\n",
        "    total_reward += reward\n",
        "  # print('Total Reward Collected: {}' .format(total_reward))\n",
        "  sarsa_l_ep_rewards.append(total_reward)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWy1d6xkGKWN",
        "outputId": "ed56c913-0962-402c-8271-da8aa0bbe9c1"
      },
      "source": [
        "# Comparison\n",
        "print('Average reward over {} trails for Semi Gradient Sarsa(0): {}'.format(num_iters, np.mean(sarsa_ep_rewards)))\n",
        "print('Standard Deviation reward over {} trails for Semi Gradient Sarsa(0): {}'.format(num_iters, np.std(sarsa_ep_rewards)))\n",
        "\n",
        "print('Average reward over {} trails for Sarsa lambda: {}'.format(num_iters, np.mean(sarsa_l_ep_rewards)))\n",
        "print('Standard Deviation reward over {} trails for Sarsa lambda: {}'.format(num_iters, np.std(sarsa_l_ep_rewards)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average reward over 100 trails for Semi Gradient Sarsa(0): 93.8\n",
            "Standard Deviation reward over 100 trails for Semi Gradient Sarsa(0): 14.542351941828391\n",
            "Average reward over 100 trails for Sarsa lambda: 99.3\n",
            "Standard Deviation reward over 100 trails for Sarsa lambda: 0.9539392014169458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xsyFk8LWGgVa",
        "outputId": "c334bbb6-a3f9-49e8-cbef-e86f64d097c7"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(['Semi Gradient SARSA(0)','SARSA(Î») with Linear Appromixation'], [np.mean(sarsa_ep_rewards), np.mean(sarsa_l_ep_rewards)], yerr=[np.std(sarsa_ep_rewards), np.std(sarsa_l_ep_rewards)], align='center', alpha=0.5, ecolor='black', capsize=5, width=[.4]*2)\n",
        "plt.title('Error plot for Semi Gradient SARSA(0) vs SARSA(Î») with Linear Appromixation with {} episodes'.format(num_iters))\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.xlabel('Policy')\n",
        "plt.xticks(['Semi Gradient SARSA(0)','SARSA(Î») with Linear Appromixation'])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gxcLuumW_mu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}